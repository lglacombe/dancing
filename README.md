# ü§ñ Rob√¥ Humanoide Core√≥grafo com Intelig√™ncia Artificial

## üí° Ideia do Projeto

Rob√¥ humanoide da cintura para cima (bra√ßos e cabe√ßa), com deslocamento horizontal por meio de uma esteira. O rob√¥ √© capaz de realizar coreografias sincronizadas com qualquer m√∫sica selecionada, utilizando intelig√™ncia artificial para gerar os movimentos de forma aut√¥noma e criativa.

## üî© Hardware Utilizado

- **9 Servo-motores** para controle individual de articula√ß√µes (bra√ßos, cabe√ßa, etc.), garantindo movimentos precisos.
- **Shield Servo de 16 canais**, permitindo que o Arduino controle m√∫ltiplos servos simultaneamente.
- **Motor DC** para locomo√ß√£o por esteira.
- **Shield Motor**, respons√°vel pelo controle do motor DC.

<img width="600" alt="hardware" src="https://github.com/user-attachments/assets/cc69fa6f-24c2-43e7-8202-1652f50d13de" />

## üõ†Ô∏è Estrutura e Montagem

Toda a estrutura f√≠sica do rob√¥ foi:

- Modelada no **SolidWorks** üíª
- Exportada no formato **STL** e impressa em **PLA** üñ®Ô∏è
- Montada com o uso de **parafusos** e **cola quente** para fixa√ß√£o dos servos

<img width="400" alt="estrutura" src="https://github.com/user-attachments/assets/6be24647-575c-4353-ad9b-f4171cf2be1f" />

## üéÆ Funcionamento do C√≥digo (servo_control.ino)

O c√≥digo implementa um sistema de controle de movimentos para um rob√¥ humanoide com 9 servos, representando articula√ß√µes como m√£os, cotovelos, ombros e cabe√ßa. Cada movimento √© composto por uma sequ√™ncia de poses, armazenadas em uma matriz de √¢ngulos.

A l√≥gica principal funciona da seguinte forma:

- O rob√¥ recebe comandos via **porta serial** (ex: `happy`, `sad`, `neutral`, etc.);
- A fun√ß√£o `execute_move()` percorre a sequ√™ncia de poses associada ao comando;
- Cada pose define os √¢ngulos desejados para os 9 servos;
- O c√≥digo realiza a interpola√ß√£o entre a posi√ß√£o atual e a nova, movimentando os servos suavemente;
- Entre cada pose h√° uma pequena pausa, criando o efeito de anima√ß√£o cont√≠nua.

Al√©m disso, o c√≥digo conta com fun√ß√µes auxiliares:

- `reset_servos()`: Define os √¢ngulos iniciais dos servos;
- `set_pose(pose[])`: Define uma pose-alvo para os servos;
- `set_angle(channel, angle)`: Converte o √¢ngulo em pulso PWM e envia para o servo.

√â poss√≠vel adicionar novos movimentos criando um vetor de poses e preenchendo uma estrutura `Move` com o n√∫mero de poses, velocidade e matriz de √¢ngulos.

## üéµ Integra√ß√£o com Spotify e Controle de Movimentos

O sistema utiliza a biblioteca [Spotipy](https://spotipy.readthedocs.io/) para se conectar √† API do Spotify e controlar a reprodu√ß√£o de m√∫sicas. Ap√≥s a autentica√ß√£o, o usu√°rio deve configurar uma **sa√≠da de √°udio est√©reo mix** compat√≠vel com o gravador do sistema (deve ser testado experimentalmente no computador em uso).

A partir disso, o processo segue dois cen√°rios:

1. **M√∫sicas n√£o gravadas**:  
   - O sistema grava a m√∫sica em reprodu√ß√£o via stereo mix;
   - O √°udio √© salvo como `.mp3` e processado por um modelo de transcri√ß√£o (como **Whisper**);
   - √â gerado um arquivo `.json` que associa trechos temporais da m√∫sica a gestos espec√≠ficos.

2. **M√∫sicas j√° gravadas**:  
   - Ao tocar uma m√∫sica com um `.json` correspondente, o sistema compara o tempo atual da m√∫sica com os tempos definidos no arquivo;
   - Quando um gesto estiver dentro do intervalo correto, ele √© enviado ao **Arduino** via uma thread separada, garantindo que a interface com o usu√°rio permane√ßa responsiva;
   - O gesto √© enviado em formato simples, apenas com a identifica√ß√£o do movimento a ser executado naquele instante.

Esse mecanismo permite que o rob√¥ execute coreografias sincronizadas com qualquer m√∫sica reproduzida no Spotify.



Intera√ß√£o com a IA

"""
Primeiramente estabelecesse uma comunica√ß√£o com a API do Spotify utilizando da biblioteca do spotipy e da interface com o usu√°rio para controlar qual m√∫sica ser√° tocada,
e seus instantes de reprodu√ß√£o, ap√≥s isso temos 2 cen√°rios poss√≠veis, 
m√∫sicas j√° gravadas e m√∫sicas n√£o gravadas, se a m√∫sica j√° n√£o tiver sido gravada ser√° feita a grava√ß√£o da m√∫sica atrav√©s de stereo mix e salva-la como mp3
para, atrav√©s do uso da local whisper transcrevenmos a musica, obtendo tamb√©m o timestamp de cada frase, assim que a trasncri√ß√£o √© completa enviamos um Prompt contendo um json como OUTPUT model,
e a letra da musica trascrita da musica, a seguir o promt:
output_model =

[   {

     "start_time": "00:00",

     "end_time": "00:05",

    "actions": [   

   { "type": "gesture", "name": "hands_up" },

 { "type": "movement", "name": "move_right", "repeat": 2, "speed": "fast"}

   ]   },

 {   

"start_time": "00:05",  

 "end_time": "00:08",   

"actions": [   

  { "type": "movement", "name": "bounce", "speed": "slow" }   

]

  } ]

F-string prompt = Prompt Title:
Generate Expressive Choreography for a Humanoid Robot Based on Timed Song Lyrics

Prompt:

You are choreographing a performance for a humanoid robot based on a song's lyrics and timestamps. The robot has articulated shoulders and arms and is capable of coordinated full-body movements across a horizontal scale ranging from 0 to 100, with its current position at {{current_position}}.

Robot Capabilities
1. Horizontal Body Movement (each moves the robot 10 units):
move_left: Moves the robot 10 units to the left.

move_right: Moves the robot 10 units to the right.

These commands can be:

Repeated to achieve larger displacements (e.g., two move_left = 20 units).

Combined with arm gestures in the same timestamp window.

bounce: A predefined rhythmic sequence: left ‚Üí right ‚Üí left ‚Üí right.

2. Pre-Programmed Arm Gestures:
hands_in_heart

hands_in_head

hands_up

left_hand_up

left_hand_down

left_hand_front_to_left

right_hand_up

right_hand_down

right_hand_front_to_right

These gestures can be used alone or combined with horizontal movements in a single interval and can be Assigned a speed modifier: slow, neutral (default), or fast..

Your Objective
Given a list of lyrics with timestamps, assign meaningful and expressive robot commands that match the rhythm, mood, and energy of each lyrical segment. Ensure the choreography:

Enhances the performance visually and emotionally.

Reflects sentiment changes in the lyrics.

Uses smooth and logical transitions.

Respects the robot‚Äôs movement capabilities and boundaries (0‚Äì100 range).
IMPORTANT INSTRUCTIONS:
1. Always use MM:SS format for timestamps (e.g. 00:00, 01:30)
2. Only output the JSON array, without any additional text or explanations
3. Follow exactly this example format:

Letra:
\n{musica}

Output Format
Produce an array of commands in this structured format:
\n{output_model}
""" 
Esse prompt √© ent√£o enviado para o gemini que retorna o json estruturado e pronto para servir de estrutura de dados de envio para o arduino. 
ap√≥s o Json conclu√≠do ca√≠mos no outro caso onde agora temos uma m√∫sica gravada sendo reproduzida, ao iniciar a reprodu√ß√£o de uma m√∫sica com Json de mesmo nome, 
ser√° comparado os tempos dos movimentos no Json com o tempo atual da m√∫sica, ao entrar dentro do intervalo ser√° enviado um comando para o Arduino atrav√©s de uma tread em separado
para n√£o travar a interface com o usu√°rio. 
Esse envio ser√° formatado para enviar somente o gesto a ser reproduzido naquele instante.¬†{Arduino}
